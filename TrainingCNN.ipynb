{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/okitouni/.conda/envs/desi/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import regularizers, callbacks\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import (Input, Dense, Activation, ZeroPadding1D, \n",
    "BatchNormalization, Flatten, Reshape, Conv1D, MaxPooling1D, Dropout,Add, LSTM,Embedding)\n",
    "from keras.initializers import glorot_normal, glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "from desispec.interpolation import resample_flux\n",
    "\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=plt.cm.tab10.colors)\n",
    "#plt.rcParamsDefault['axes.prop_cycle']\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "plt.rc('grid',alpha=0.3,linestyle='--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def network(input_shape, learning_rate=0.0005, reg=0.0032, dropout=0.7436, seed=None):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "    input_shape -- shape of the input spectra\n",
    "    regularization_strength -- regularization factor\n",
    "    dropout -- dropout rate\n",
    "    seed -- seed of initializer\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    X_input = Input(input_shape, name='Input_Spec')\n",
    "\n",
    "    with K.name_scope('Conv_1'):\n",
    "        X = Conv1D(filters=8, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X_input)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(pool_size= 2)(X)\n",
    "\n",
    "    with K.name_scope('Conv_2'):\n",
    "        X = Conv1D(filters=16, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "    with K.name_scope('Conv_3'):\n",
    "        X = Conv1D(filters=32, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "        \n",
    "    with K.name_scope('Conv_4'):\n",
    "        X = Conv1D(filters=64, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "\n",
    "        \n",
    "    # FLATTEN -> FULLYCONNECTED\n",
    "    with K.name_scope('Dense_Layer'):\n",
    "        X = Flatten()(X)\n",
    "        X = Dense(256, kernel_regularizer=regularizers.l2(reg),\n",
    "                  activation='relu')(X)\n",
    "        X = Dropout(rate=dropout, seed=seed)(X)\n",
    "    \n",
    "    with K.name_scope('Output_Layer'):\n",
    "        X = Dense(1, kernel_regularizer=regularizers.l2(reg),\n",
    "              activation='sigmoid',name='Output_Classes')(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='SNnet')\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = network((400,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_host = np.sort(glob.glob('/scratch/sbenzvi/desi/time-domain/bgs/hosts/*/*coadd.fits'))\n",
    "flux_host = []\n",
    "for f in files_host:\n",
    "    h = fits.open(f)\n",
    "    fl = h[1].data\n",
    "    flux_host.append(fl)\n",
    "fluxes_hosts = np.concatenate(flux_host)\n",
    "fluxes_hosts = fluxes_hosts[fluxes_hosts.sum(axis=1)!=0]\n",
    "subspec_hosts = np.mean(fluxes_hosts[:,:6000].reshape(-1,400,15),2)\n",
    "maxflux = fluxes_hosts.max(axis=-1).reshape(-1,1)\n",
    "minflux = fluxes_hosts.min(axis=-1).reshape(-1,1)\n",
    "standarized_hosts = (subspec_hosts - minflux)/(maxflux-minflux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = np.sort(glob.glob('/scratch/sbenzvi/desi/time-domain/bgs/sne_ia/*/*coadd.fits'))\n",
    "flux = []\n",
    "for f in files:\n",
    "    h = fits.open(f)\n",
    "    f = h[1].data\n",
    "    zeros = np.zeros(400)\n",
    "    flux.append(f)\n",
    "fluxes = np.concatenate(flux)\n",
    "fluxes = fluxes[fluxes.sum(axis=1)!=0]\n",
    "subspec = np.mean(fluxes[:,:6000].reshape(-1,400,15),2)\n",
    "maxflux = fluxes.max(axis=-1).reshape(-1,1)\n",
    "minflux = fluxes.min(axis=-1).reshape(-1,1)\n",
    "standarized = (subspec - minflux)/(maxflux-minflux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([standarized,standarized_hosts]).reshape(-1,400,1)\n",
    "y_train = np.concatenate([np.zeros(standarized.shape[0]),np.ones(standarized_hosts.shape[0])])\n",
    "permute = np.random.permutation(y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      "27000/27000 [==============================] - 47s 2ms/step - loss: 1.5754 - acc: 0.5574 - val_loss: 1.1333 - val_acc: 0.5753\n",
      "Epoch 2/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.9455 - acc: 0.6300 - val_loss: 0.8659 - val_acc: 0.5967\n",
      "Epoch 3/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.6768 - acc: 0.7548 - val_loss: 1.3656 - val_acc: 0.4483\n",
      "Epoch 4/50\n",
      "27000/27000 [==============================] - 45s 2ms/step - loss: 0.5765 - acc: 0.7947 - val_loss: 0.6615 - val_acc: 0.7027\n",
      "Epoch 5/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.5258 - acc: 0.8133 - val_loss: 0.9394 - val_acc: 0.5907\n",
      "Epoch 6/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.4909 - acc: 0.8306 - val_loss: 2.0243 - val_acc: 0.4473\n",
      "Epoch 7/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.4607 - acc: 0.8423 - val_loss: 0.9979 - val_acc: 0.6200\n",
      "Epoch 8/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.4502 - acc: 0.8483 - val_loss: 0.8174 - val_acc: 0.7067\n",
      "Epoch 9/50\n",
      "27000/27000 [==============================] - 45s 2ms/step - loss: 0.4381 - acc: 0.8499 - val_loss: 3.8260 - val_acc: 0.5557\n",
      "Epoch 10/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.4219 - acc: 0.8580 - val_loss: 0.9167 - val_acc: 0.5907\n",
      "Epoch 11/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.4190 - acc: 0.8577 - val_loss: 0.6874 - val_acc: 0.7080\n",
      "Epoch 12/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.4121 - acc: 0.8604 - val_loss: 1.0422 - val_acc: 0.6483\n",
      "Epoch 13/50\n",
      "27000/27000 [==============================] - 45s 2ms/step - loss: 0.4021 - acc: 0.8638 - val_loss: 0.8380 - val_acc: 0.6870\n",
      "Epoch 14/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3936 - acc: 0.8694 - val_loss: 0.4157 - val_acc: 0.8403\n",
      "Epoch 15/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3892 - acc: 0.8683 - val_loss: 0.8697 - val_acc: 0.6127\n",
      "Epoch 16/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3819 - acc: 0.8739 - val_loss: 1.1008 - val_acc: 0.5910\n",
      "Epoch 17/50\n",
      "27000/27000 [==============================] - 44s 2ms/step - loss: 0.3769 - acc: 0.8763 - val_loss: 4.8751 - val_acc: 0.5730\n",
      "Epoch 18/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3734 - acc: 0.8765 - val_loss: 0.5654 - val_acc: 0.7457\n",
      "Epoch 19/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3724 - acc: 0.8749 - val_loss: 0.6967 - val_acc: 0.6743\n",
      "Epoch 20/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3671 - acc: 0.8789 - val_loss: 1.1321 - val_acc: 0.4673\n",
      "Epoch 21/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3673 - acc: 0.8779 - val_loss: 0.5919 - val_acc: 0.7580\n",
      "Epoch 22/50\n",
      "27000/27000 [==============================] - 45s 2ms/step - loss: 0.3600 - acc: 0.8811 - val_loss: 0.4465 - val_acc: 0.8223\n",
      "Epoch 23/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3566 - acc: 0.8825 - val_loss: 0.6959 - val_acc: 0.6913\n",
      "Epoch 24/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3620 - acc: 0.8792 - val_loss: 0.4018 - val_acc: 0.8490\n",
      "Epoch 25/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3505 - acc: 0.8876 - val_loss: 2.7732 - val_acc: 0.5633\n",
      "Epoch 26/50\n",
      "27000/27000 [==============================] - 44s 2ms/step - loss: 0.3546 - acc: 0.8817 - val_loss: 0.8050 - val_acc: 0.7253\n",
      "Epoch 27/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3496 - acc: 0.8853 - val_loss: 0.8608 - val_acc: 0.7033\n",
      "Epoch 28/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3510 - acc: 0.8848 - val_loss: 0.7510 - val_acc: 0.6260\n",
      "Epoch 29/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3473 - acc: 0.8863 - val_loss: 0.5113 - val_acc: 0.8040\n",
      "Epoch 30/50\n",
      "27000/27000 [==============================] - 44s 2ms/step - loss: 0.3401 - acc: 0.8901 - val_loss: 0.8443 - val_acc: 0.6323\n",
      "Epoch 31/50\n",
      "27000/27000 [==============================] - 44s 2ms/step - loss: 0.3407 - acc: 0.8886 - val_loss: 0.6821 - val_acc: 0.6967\n",
      "Epoch 32/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3411 - acc: 0.8891 - val_loss: 2.0694 - val_acc: 0.6223\n",
      "Epoch 33/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3383 - acc: 0.8917 - val_loss: 0.4385 - val_acc: 0.8240\n",
      "Epoch 34/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3377 - acc: 0.8905 - val_loss: 0.4043 - val_acc: 0.8480\n",
      "Epoch 35/50\n",
      "27000/27000 [==============================] - 45s 2ms/step - loss: 0.3372 - acc: 0.8909 - val_loss: 0.4164 - val_acc: 0.8380\n",
      "Epoch 36/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3361 - acc: 0.8924 - val_loss: 0.5654 - val_acc: 0.7613\n",
      "Epoch 37/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3323 - acc: 0.8943 - val_loss: 0.3973 - val_acc: 0.8513\n",
      "Epoch 38/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3318 - acc: 0.8917 - val_loss: 0.4867 - val_acc: 0.7973\n",
      "Epoch 39/50\n",
      "27000/27000 [==============================] - 45s 2ms/step - loss: 0.3295 - acc: 0.8950 - val_loss: 0.6665 - val_acc: 0.6977\n",
      "Epoch 40/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3265 - acc: 0.8959 - val_loss: 0.5472 - val_acc: 0.7860\n",
      "Epoch 41/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3247 - acc: 0.8975 - val_loss: 0.7879 - val_acc: 0.6440\n",
      "Epoch 42/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3231 - acc: 0.8981 - val_loss: 0.7303 - val_acc: 0.7093\n",
      "Epoch 43/50\n",
      "27000/27000 [==============================] - 45s 2ms/step - loss: 0.3257 - acc: 0.8962 - val_loss: 0.6069 - val_acc: 0.7333\n",
      "Epoch 44/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3198 - acc: 0.8993 - val_loss: 1.1225 - val_acc: 0.6907\n",
      "Epoch 45/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3257 - acc: 0.8971 - val_loss: 0.7985 - val_acc: 0.5950\n",
      "Epoch 46/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3206 - acc: 0.9002 - val_loss: 0.4117 - val_acc: 0.8567\n",
      "Epoch 47/50\n",
      "27000/27000 [==============================] - 45s 2ms/step - loss: 0.3235 - acc: 0.8980 - val_loss: 0.7290 - val_acc: 0.6603\n",
      "Epoch 48/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3202 - acc: 0.9017 - val_loss: 0.4286 - val_acc: 0.8463\n",
      "Epoch 49/50\n",
      "27000/27000 [==============================] - 42s 2ms/step - loss: 0.3194 - acc: 0.9013 - val_loss: 0.3616 - val_acc: 0.8683\n",
      "Epoch 50/50\n",
      "27000/27000 [==============================] - 43s 2ms/step - loss: 0.3207 - acc: 0.9011 - val_loss: 1.2407 - val_acc: 0.6467\n"
     ]
    }
   ],
   "source": [
    "hist = model2.fit(x_train[permute][:30000],y_train[permute][:30000],batch_size=64,epochs=50,\n",
    "                  validation_split=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 0.5152 - acc: 0.8145 - val_loss: 0.4730 - val_acc: 0.8400\n",
      "Epoch 2/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.4593 - acc: 0.8448 - val_loss: 0.4879 - val_acc: 0.8093\n",
      "Epoch 3/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.4476 - acc: 0.8493 - val_loss: 0.4673 - val_acc: 0.8300\n",
      "Epoch 4/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 0.4382 - acc: 0.8495 - val_loss: 0.8181 - val_acc: 0.6293\n",
      "Epoch 5/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.4300 - acc: 0.8540 - val_loss: 0.6477 - val_acc: 0.7097\n",
      "Epoch 6/100\n",
      "27000/27000 [==============================] - 144s 5ms/step - loss: 0.4245 - acc: 0.8548 - val_loss: 0.4767 - val_acc: 0.8240\n",
      "Epoch 7/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 0.4175 - acc: 0.8587 - val_loss: 0.4660 - val_acc: 0.8237\n",
      "Epoch 8/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 0.4126 - acc: 0.8590 - val_loss: 0.5252 - val_acc: 0.7890\n",
      "Epoch 9/100\n",
      "27000/27000 [==============================] - 144s 5ms/step - loss: 0.4142 - acc: 0.8603 - val_loss: 0.4337 - val_acc: 0.8420\n",
      "Epoch 10/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 0.4106 - acc: 0.8602 - val_loss: 0.4188 - val_acc: 0.8487\n",
      "Epoch 11/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 0.4031 - acc: 0.8637 - val_loss: 0.7432 - val_acc: 0.6073\n",
      "Epoch 12/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 0.4026 - acc: 0.8626 - val_loss: 0.4673 - val_acc: 0.8137\n",
      "Epoch 13/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 0.4002 - acc: 0.8615 - val_loss: 0.8527 - val_acc: 0.5567\n",
      "Epoch 14/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 0.3969 - acc: 0.8646 - val_loss: 0.4618 - val_acc: 0.8213\n",
      "Epoch 15/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 0.3988 - acc: 0.8636 - val_loss: 0.4528 - val_acc: 0.8180\n",
      "Epoch 16/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 0.3968 - acc: 0.8669 - val_loss: 0.4712 - val_acc: 0.8147\n",
      "Epoch 17/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 0.3952 - acc: 0.8636 - val_loss: 0.3827 - val_acc: 0.8670\n",
      "Epoch 18/100\n",
      "27000/27000 [==============================] - 144s 5ms/step - loss: 0.3910 - acc: 0.8650 - val_loss: 0.4900 - val_acc: 0.7987\n",
      "Epoch 19/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 0.3940 - acc: 0.8643 - val_loss: 0.4001 - val_acc: 0.8580\n",
      "Epoch 20/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 0.3897 - acc: 0.8667 - val_loss: 0.4774 - val_acc: 0.8153\n",
      "Epoch 21/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 0.3882 - acc: 0.8679 - val_loss: 0.5429 - val_acc: 0.7873\n",
      "Epoch 22/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.3870 - acc: 0.8676 - val_loss: 0.5996 - val_acc: 0.7133\n",
      "Epoch 23/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 0.3898 - acc: 0.8661 - val_loss: 0.4578 - val_acc: 0.8130\n",
      "Epoch 24/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 0.3843 - acc: 0.8708 - val_loss: 0.8525 - val_acc: 0.6093\n",
      "Epoch 25/100\n",
      "27000/27000 [==============================] - 144s 5ms/step - loss: 0.3840 - acc: 0.8693 - val_loss: 0.4196 - val_acc: 0.8530\n",
      "Epoch 26/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 0.3851 - acc: 0.8668 - val_loss: 0.5018 - val_acc: 0.8003\n",
      "Epoch 27/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 0.3835 - acc: 0.8681 - val_loss: 0.4867 - val_acc: 0.7993\n",
      "Epoch 28/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 0.3854 - acc: 0.8679 - val_loss: 0.4720 - val_acc: 0.8033\n",
      "Epoch 29/100\n",
      "27000/27000 [==============================] - 137s 5ms/step - loss: 0.3815 - acc: 0.8686 - val_loss: 0.4264 - val_acc: 0.8427\n",
      "Epoch 30/100\n",
      "27000/27000 [==============================] - 145s 5ms/step - loss: 0.3847 - acc: 0.8661 - val_loss: 0.3959 - val_acc: 0.8590\n",
      "Epoch 31/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.3817 - acc: 0.8700 - val_loss: 0.5144 - val_acc: 0.7913\n",
      "Epoch 32/100\n",
      "27000/27000 [==============================] - 144s 5ms/step - loss: 0.3804 - acc: 0.8701 - val_loss: 0.3839 - val_acc: 0.8667\n",
      "Epoch 33/100\n",
      "27000/27000 [==============================] - 144s 5ms/step - loss: 0.3819 - acc: 0.8698 - val_loss: 0.4020 - val_acc: 0.8583\n",
      "Epoch 34/100\n",
      "27000/27000 [==============================] - 144s 5ms/step - loss: 0.3828 - acc: 0.8691 - val_loss: 0.4644 - val_acc: 0.8150\n",
      "Epoch 35/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.3777 - acc: 0.8714 - val_loss: 0.4154 - val_acc: 0.8433\n",
      "Epoch 36/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 0.3778 - acc: 0.8702 - val_loss: 0.3758 - val_acc: 0.8683\n",
      "Epoch 37/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 0.3780 - acc: 0.8707 - val_loss: 0.5896 - val_acc: 0.7373\n",
      "Epoch 38/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 0.3785 - acc: 0.8706 - val_loss: 0.4714 - val_acc: 0.8137\n",
      "Epoch 39/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 0.3796 - acc: 0.8690 - val_loss: 0.4147 - val_acc: 0.8447\n",
      "Epoch 40/100\n",
      "27000/27000 [==============================] - 137s 5ms/step - loss: 0.3772 - acc: 0.8700 - val_loss: 0.6416 - val_acc: 0.6923\n",
      "Epoch 41/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 0.3776 - acc: 0.8692 - val_loss: 0.3629 - val_acc: 0.8740\n",
      "Epoch 42/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 0.3801 - acc: 0.8681 - val_loss: 0.4117 - val_acc: 0.8553\n",
      "Epoch 43/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 0.3763 - acc: 0.8698 - val_loss: 0.3818 - val_acc: 0.8640\n",
      "Epoch 44/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 0.3765 - acc: 0.8705 - val_loss: 0.3786 - val_acc: 0.8597\n",
      "Epoch 45/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 0.3797 - acc: 0.8676 - val_loss: 0.4115 - val_acc: 0.8570\n",
      "Epoch 46/100\n",
      "27000/27000 [==============================] - 135s 5ms/step - loss: 0.3758 - acc: 0.8712 - val_loss: 0.6342 - val_acc: 0.7037\n",
      "Epoch 47/100\n",
      "27000/27000 [==============================] - 136s 5ms/step - loss: 0.3798 - acc: 0.8696 - val_loss: 0.4160 - val_acc: 0.8347\n",
      "Epoch 48/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 0.3768 - acc: 0.8706 - val_loss: 0.5552 - val_acc: 0.7923\n",
      "Epoch 49/100\n",
      "27000/27000 [==============================] - 145s 5ms/step - loss: 0.3762 - acc: 0.8695 - val_loss: 0.3935 - val_acc: 0.8577\n",
      "Epoch 50/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 0.3774 - acc: 0.8705 - val_loss: 0.4769 - val_acc: 0.8110\n",
      "Epoch 51/100\n",
      " 7480/27000 [=======>......................] - ETA: 1:38 - loss: 0.3704 - acc: 0.8741"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(x_train[permute][:30000],y_train[permute][:30000],batch_size=4,epochs=100,\n",
    "                  validation_split=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 161244 samples, validate on 17917 samples\n",
      "Epoch 1/50\n",
      "161244/161244 [==============================] - 206s 1ms/step - loss: 0.7901 - acc: 0.7280 - val_loss: 0.9118 - val_acc: 0.6655\n",
      "Epoch 2/50\n",
      "161244/161244 [==============================] - 203s 1ms/step - loss: 0.4447 - acc: 0.8437 - val_loss: 0.7148 - val_acc: 0.7388\n",
      "Epoch 3/50\n",
      "161244/161244 [==============================] - 208s 1ms/step - loss: 0.3960 - acc: 0.8624 - val_loss: 0.5286 - val_acc: 0.7645\n",
      "Epoch 4/50\n",
      "161244/161244 [==============================] - 198s 1ms/step - loss: 0.3775 - acc: 0.8681 - val_loss: 0.7683 - val_acc: 0.6891\n",
      "Epoch 5/50\n",
      "161244/161244 [==============================] - 205s 1ms/step - loss: 0.3653 - acc: 0.8735 - val_loss: 0.4605 - val_acc: 0.8005\n",
      "Epoch 6/50\n",
      "161244/161244 [==============================] - 212s 1ms/step - loss: 0.3557 - acc: 0.8761 - val_loss: 1.2020 - val_acc: 0.6592\n",
      "Epoch 7/50\n",
      "161244/161244 [==============================] - 203s 1ms/step - loss: 0.3466 - acc: 0.8792 - val_loss: 0.6965 - val_acc: 0.6906\n",
      "Epoch 8/50\n",
      "161244/161244 [==============================] - 201s 1ms/step - loss: 0.3405 - acc: 0.8810 - val_loss: 0.6198 - val_acc: 0.7096\n",
      "Epoch 9/50\n",
      "161244/161244 [==============================] - 205s 1ms/step - loss: 0.3388 - acc: 0.8823 - val_loss: 0.9715 - val_acc: 0.5396\n",
      "Epoch 10/50\n",
      "161244/161244 [==============================] - 219s 1ms/step - loss: 0.3337 - acc: 0.8837 - val_loss: 0.8326 - val_acc: 0.5530\n",
      "Epoch 11/50\n",
      "161244/161244 [==============================] - 215s 1ms/step - loss: 0.3304 - acc: 0.8848 - val_loss: 1.2325 - val_acc: 0.4715\n",
      "Epoch 12/50\n",
      "161244/161244 [==============================] - 198s 1ms/step - loss: 0.3293 - acc: 0.8852 - val_loss: 0.3243 - val_acc: 0.8848\n",
      "Epoch 13/50\n",
      "161244/161244 [==============================] - 204s 1ms/step - loss: 0.3270 - acc: 0.8859 - val_loss: 0.3690 - val_acc: 0.8549\n",
      "Epoch 14/50\n",
      "161244/161244 [==============================] - 199s 1ms/step - loss: 0.3253 - acc: 0.8867 - val_loss: 0.7373 - val_acc: 0.6418\n",
      "Epoch 15/50\n",
      "161244/161244 [==============================] - 205s 1ms/step - loss: 0.3241 - acc: 0.8875 - val_loss: 0.5921 - val_acc: 0.7258\n",
      "Epoch 16/50\n",
      "161244/161244 [==============================] - 208s 1ms/step - loss: 0.3228 - acc: 0.8877 - val_loss: 0.6561 - val_acc: 0.6665\n",
      "Epoch 17/50\n",
      "161244/161244 [==============================] - 219s 1ms/step - loss: 0.3210 - acc: 0.8881 - val_loss: 0.3254 - val_acc: 0.8833\n",
      "Epoch 18/50\n",
      "161244/161244 [==============================] - 218s 1ms/step - loss: 0.3216 - acc: 0.8875 - val_loss: 0.3581 - val_acc: 0.8624\n",
      "Epoch 19/50\n",
      "161244/161244 [==============================] - 187s 1ms/step - loss: 0.3187 - acc: 0.8893 - val_loss: 0.3046 - val_acc: 0.8948\n",
      "Epoch 20/50\n",
      "161244/161244 [==============================] - 186s 1ms/step - loss: 0.3188 - acc: 0.8897 - val_loss: 0.4435 - val_acc: 0.8132\n",
      "Epoch 21/50\n",
      "161244/161244 [==============================] - 186s 1ms/step - loss: 0.3178 - acc: 0.8888 - val_loss: 0.3556 - val_acc: 0.8625\n",
      "Epoch 22/50\n",
      "161244/161244 [==============================] - 186s 1ms/step - loss: 0.3166 - acc: 0.8894 - val_loss: 0.4464 - val_acc: 0.8199\n",
      "Epoch 23/50\n",
      "161244/161244 [==============================] - 186s 1ms/step - loss: 0.3162 - acc: 0.8904 - val_loss: 0.3525 - val_acc: 0.8658\n",
      "Epoch 24/50\n",
      "161244/161244 [==============================] - 186s 1ms/step - loss: 0.3169 - acc: 0.8891 - val_loss: 0.6637 - val_acc: 0.6694\n",
      "Epoch 25/50\n",
      "161244/161244 [==============================] - 186s 1ms/step - loss: 0.3153 - acc: 0.8904 - val_loss: 0.5195 - val_acc: 0.7513\n",
      "Epoch 26/50\n",
      "161244/161244 [==============================] - 186s 1ms/step - loss: 0.3143 - acc: 0.8903 - val_loss: 0.3440 - val_acc: 0.8686\n",
      "Epoch 27/50\n",
      "161244/161244 [==============================] - 186s 1ms/step - loss: 0.3143 - acc: 0.8898 - val_loss: 0.7929 - val_acc: 0.5779\n",
      "Epoch 28/50\n",
      "161244/161244 [==============================] - 186s 1ms/step - loss: 0.3149 - acc: 0.8900 - val_loss: 1.0067 - val_acc: 0.4752\n",
      "Epoch 29/50\n",
      "161244/161244 [==============================] - 186s 1ms/step - loss: 0.3143 - acc: 0.8903 - val_loss: 0.3915 - val_acc: 0.8443\n",
      "Epoch 30/50\n",
      "161244/161244 [==============================] - 186s 1ms/step - loss: 0.3134 - acc: 0.8907 - val_loss: 0.6611 - val_acc: 0.6626\n",
      "Epoch 31/50\n",
      "161244/161244 [==============================] - 186s 1ms/step - loss: 0.3131 - acc: 0.8913 - val_loss: 0.5869 - val_acc: 0.7046\n",
      "Epoch 32/50\n",
      "161244/161244 [==============================] - 185s 1ms/step - loss: 0.3123 - acc: 0.8911 - val_loss: 0.3143 - val_acc: 0.8865\n",
      "Epoch 33/50\n",
      "161244/161244 [==============================] - 185s 1ms/step - loss: 0.3122 - acc: 0.8912 - val_loss: 0.3686 - val_acc: 0.8551\n",
      "Epoch 34/50\n",
      "161244/161244 [==============================] - 186s 1ms/step - loss: 0.3129 - acc: 0.8902 - val_loss: 0.3356 - val_acc: 0.8740\n",
      "Epoch 35/50\n",
      "  5504/161244 [>.............................] - ETA: 2:53 - loss: 0.3226 - acc: 0.8888"
     ]
    }
   ],
   "source": [
    "hist = model2.fit(x_train[permute],y_train[permute],batch_size=64,epochs=50,\n",
    "                  validation_split=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (anaconda3 5.3.0)/ DESI",
   "language": "python",
   "name": "anaconda3-5.3.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
